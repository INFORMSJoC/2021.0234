decentr markov decis process dec-mdp popular model agent-coordin problem domain uncertainti time constraint veri difficult paper state-of-the-art heurist solut method dec-mdp oc-dec-mdp recent dec-mdp heurist solut method valu function propag vfp orthogon improv oc-dec-mdp first oc-decmdp order magnitud valu function state function time rather separ valu pair sate time interv furthermor solut qualiti oc-dec-mdp becaus analyt result not expect total reward oc-dec- mdp improv independ crisis-manag domain as well other type domain experiment result signific speedup vfp over oc-dec-mdp as well solut qualiti varieti situat categori subject descriptor i211 [ artifici intellig ] artifici intelligencemulti-ag system gener term algorithm theori develop algorithm effect coordin multipl agent team uncertain time critic domain recent veri activ research field potenti applic coordin agent hostag rescu mission ] coordin autonom mar explor rover ] uncertain dynam characterist such domain decision-theoret model lot attent recent year mainli thank express abil reason util action time key decision-theoret model popular literatur decentr markov decis process decmdp decentr partial observ markov decis process dec-pomdp unfortun model optim nexp-complet [ ] henc tractabl subclass model subject intens research particular network distribut pomdp ] not agent interact other transit independ dec-mdp [ ] transit function decompos local transit function dec-mdp event driven interact ] interact agent fix time point good exampl such subclass global optim algorithm subclass promis result domain algorithm still small time horizon onli few time tick local optim algorithm ] ] ] particular opportun cost dec-mdp [ ] ] oc-dec-mdp particularli notabl domain hundr task doubl digit time horizon addit oc-dec-mdp uniqu abil tempor constraint uncertain method execut durat import factor real-world domain oc-dec-mdp abl such domain mainli instead global optim solut seri polici iter iter valu iter data previou polici iter howev oc-dec-mdp still slow especi time horizon number method larg valu reason high runtim oc-dec-mdp such domain consequ huge state space oc-dec-mdp separ state possibl pair method method execut interv furthermor oc-dec-mdp reward method execut futur method reward also opportun cost crucial role agent decis make later overestim highli suboptim polici context vfp = valu function p ropag effici solut techniqu dec-mdp model tempor constraint uncertain method execut durat success oc-dec-mdp vfp orthogon idea first similarli ] ] ] 978-81-904262-7-5 rp c ifaama valu function time method rather separ valu pair method time interv such represent group time point valu function chang same rate slope constant result fast function propag valu function second theoret empir oc-dec- mdp opportun cost set heurist opportun cost overestim problem paper section research civilian rescu domain team fire- brigad order civilian burn build section detail descript dec-mdp model tempor constraint section problem model global optim local optim solver section orthogon improv state-of-the-art oc-dec-mdp algorithm vfp algorithm implement final section empir impact orthogon improv i new heurist opportun cost overestim problem qualiti polici ii systemat tradeoff solut qualiti time vfp algorithm much oc-dec-mdp algorithm motiv interest domain multipl agent plan time uncertainti plan execut durat outcom exampl domain large-scal disast fire skyscrap hundr civilian numer floor multipl rescu team radio commun channel quickli useless particular small team fire-brigad separ mission civilian dozen differ locat small mission plan figur firebrigad task civilian site b site a eg offic floor gener fire fight procedur i flame ii site toxic high temperatur gase restrict ventil not too fast order fire team civilian minut fire site b unbear fire site order access site b past larg scale disast commun often henc domain commun fire-brigad fb1 fb2 fb3 consequ fb2 not alreadi safe site a fb1 not alreadi safe site fire site b reward civilian site b reward success ventil site a civilian site b clearli dilemma fb2 onli durat fight fire site method fb1 fb3 same time fb2 time civilian fb2 site a too earli fire control fb2 ventil method too long fire site b unbear civilian gener agent sequenc such est let notat section figur civilian rescu domain mission plan arrow repres implicit preced constraint agent difficult decis particular decis process fb2 first site a then time site a civilian site b such sequenc decis polici agent fast time out model descript decis problem model decentr mdp tempor constraint instanc decis problem tupl m a c p r m = mi |m| i=1 set method a = ak |a| k=1 set agent agent not mission execut agent ak set mk method such s|a| mk = m ∀i j mj = ø also method agent ak onli onc agent ak onli method time method execut time uncertain p = pi |m| i=1 set distribut method execut durat particular pi t probabl execut method mi consum time t c set tempor constraint system method partial method time window c = c≺ ∪ c [ ] c≺ set predecessor constraint c [ ] set time window constraint c ∈ c≺ = mi mj method mi preced mj ie execut mj not mi termin particular agent ak method chain predecessor constraint graph g = m c≺ acycl not node problem not independ subproblem sourc vertic sourc method system c ∈ c [ ] = mi est let execut mi onli earliest start time est latest end time let method multipl disjoint time window constraint distribut time horizon time window constraint plan horizon δ = max m τ τ ∈c [ ] τ mission deadlin final r = ri |m| i=1 set non-neg reward ri success execut mi commun agent onli probabl method alreadi also oc-dec-mdp framework model time resourc constraint sixth intl joint conf autonom agent multi-ag system aama other agent consequ ∈ mk next method agent ak current time t ∈ [ δ ] agent decis method mj e wait w case agent ak idl arbitrari small time resum oper same place method mj time t + case agent ak next method outcom possibl success agent ak reward rj move next method such method exist so long follow condit i method mi| mi c≺ directli method mj alreadi ii execut method mj time window method mj mj τ τ ∈c [ ] such ∈ [ τ τ ] iii execut method mj same time window agent ak method mj time equal − t failur above-ment condit not agent ak execut other agent execut method ∈ m| mj c≺ never enabl polici πk agent ak function πk mk × [ δ ] → w e πk m t mean ak method m time t action joint polici π = [ πk ] |a| k=1 optim π∗ sum reward agent solut techniqu optim algorithm optim joint polici π∗ usual bellman updat principl order optim polici method mj optim polici method mk ∈ m| mj c≺ unfortun model optim polici method mj also polici method mi ∈ m| m c≺ doubl depend result fact expect reward execut method mj time t also probabl mj time t consequ time δ|m| candid polici order π∗ thu global optim algorithm real-world problem unlik reason time [ ] complex model restrict version particular method mj time point t ∈ tj ⊂ [ δ ] coverag set algorithm csa ] howev csa complex doubl exponenti size ti domain tj valu local optim algorithm limit applic global optim algorithm dec-mdp tempor constraint local optim algorithm promis special oc-dec-mdp algorithm ] particularli signific easili domain hundr method idea oc-decmdp algorithm start time polici π0 agent method m as soon m non-zero chanc alreadi then iter further improv possibl iter algorithm polici π uniqu probabl pi [ τ τ ] method mi time interv [ τ τ ] then step step sink method sourc method valu vi [ τ τ ] expect util method mi time interv [ τ τ ] propag probabl pi [ τ τ ] previou algorithm iter step valu propag phase step valu vi [ τ τ ] step algorithm profit method execut interv new polici π then new probabl pi [ τ τ ] sourc method method step probabl propag phase polici π not π algorithm shortcom oc-dec-mdp algorithm paper first oc-dec-mdp state pair mj [ τ τ ] [ τ τ ] time interv method mj such state represent benefici problem standard valu iter algorithm intuit map time t total reward execut mj time t consequ method mi method mj valu vj [ τ τ ] ∀τ τ ∈ [ ] oper valu vi [ τ τ ] ∀τ τ ∈ [ valu propag phase time o i2 number time interv runtim whole algorithm proport runtim oper especi big time horizon oc- decmdp algorithm slow second oc-dec-mdp precis calcul valu vj [ τ τ ] critic issu valu vj [ τ τ ] method mj multipl method later oc-dec-mdp vj [ τ τ ] part vj [ τ τ ] up again result method method mj valu mj later disastr consequ next section shortcom valu function propag vfp gener scheme vfp algorithm ident ocdec-mdp algorithm seri polici improv iter valu probabl propag phase howev instead separ valu vfp whole function phase valu function propag phase probabl function propag phase end method mi ∈ m new function valu function vi t map time t ∈ [ δ ] total reward execut method mi time t opportun cost function vi t map time t ∈ [ δ ] total reward execut method mi time t mi probabl function pi t map time t ∈ [ δ ] probabl mi time t such function represent easili current polici agent ak method mi time t then as long valu function vi t futur formal πk mi t j w ∃t > t such vi t < vi t e otherwis now analyt techniqu valu function probabl function propag phase similarli probabl propag phase sixth intl joint conf autonom agent multi-ag system aama valu function propag phase suppos valu function propag phase valu function sink method sourc method time phase situat figur opportun cost function vjn ] n n=0 method [ mjn ] n n=0 opportun cost vi0 method mi0 pi0 probabl distribut function method mi0 execut durat ri0 immedi reward execut method mi0 time interv [ τ τ ] such mi0 τ τ ∈ c [ ] function vi0 then ri0 opportun cost vjn i0 t = n futur method formal vi0 t > > < > > r τ pi0 t ri0 + pn vjn i0 t + t dt ∃ mi0 τ τ ∈c [ ] such ∈ [ τ τ otherwis note t ∈ [ τ τ ] t = ri0 + pn vjn i0 τ −t then vi0 convolut p h vi0 t = pi0 ∗h τ −t now vjn i0 full opportun cost discuss differ techniqu opportun cost vj0 [ vj0 ik ] k k=0 section now vj0 i0 deriv vjn i0 n = same scheme fragment mdp agent ak probabl function forward valu function backward right v j0 i0 t opportun cost execut method mj0 time t method mi0 vi0 probabl function method other mi0 enabl mj0 formal v j0 i0 t = vj0 t ky k=1 pik t similarli ] ] depend [ plk ] k k=1 observ v j0 i0 not monoton execut method mi0 sometim profit opportun cost vj0 i0 t method mi0 time t equal v j0 i0 furthermor vj0 i0 non-increas formal vj0 i0 = min f∈f f f = f | f ≥ v j0 i0 f t ≥ f t < t opportun cost vi0 then easili valu function vi0 ak agent method mi0 ak execut mi0 ak part mission plan up method mi0 ak not other agent method mlk ] k=k k=1 order vi0 vi0 probabl function method other agent enabl mi0 formal vi0 t = vi0 t ky k=1 plk t depend [ plk ] k k=1 also consequ gener scheme valu function [ vjn ] n n=0 [ vjn ] n n=0 method [ mjn ] n vi0 vi0 method mi0 gener valu function propag scheme sink node then time method m such method enabl alreadi valu function propag phase sourc method polici order polici agent ak method mj0 set zj0 interv [ z z ] ⊂ [ δ ] such ∀t∈ [ z z ] πk mj0 t w one easili interv zj0 time interv valu function vj0 not monoton probabl function propag phase assum now valu function opportun cost valu sink method sourc node set zj method ∈ m valu function propag phase probabl pi t method mi ∈ m time ∈ [ δ ] previou algorithm iter now new valu pi t order algorithm next iter now gener case figur probabl function forward method probabl function pik ] k k=0 method [ mik ] k k=0 probabl function pj0 method mj0 pj0 probabl distribut function method mj0 execut durat zj0 set interv inact method mj0 last valu function propag phase depend [ pik ] k k=0 then probabl pj0 t execut method mj0 time t pj0 t = qk pik τ τ zj0 st t ∈ τ qk k=0 pik t otherwis pj0 t probabl pj0 t mj0 time t pj0 t = z z t ∂pj0 ∂t t · pj0 t − t dt dt compactli ∂pj0 ∂t = pj0 ∗ ∂p j0 ∂t consequ probabl function pik ] k k=0 method [ mik ] k k=0 probabl function pj0 method mj0 gener probabl function propag phase sourc method msi psi default then time method m such method sixth intl joint conf autonom agent multi-ag system aama m alreadi probabl function propag phase sink method algorithm similarli oc-dec-mdp algorithm vfp polici improv iter start time polici π0 then iter i valu function vi ] |m| i=1 old probabl function pi ] |m| i=1 previou algorithm iter new set zi ] |m| i=1 method inact interv ii new probabl function pi ] |m| i=1 newli set [ zi ] |m| i=1 new function pi ] |m| i=1 then next iter algorithm similarli oc-dec-mdp vfp new polici not polici previou algorithm iter implement function oper so far function oper valu function probabl function propag function represent gener function oper continu time freedom desir function approxim techniqu such piecewis ] piecewis constant [ ] approxim howev goal vfp oc-dec- mdp algorithm onli discret time also time valu function probabl function piecewis linear pwl function vfp algorithm valu function probabl function constantli oper equat alreadi oper convolut function t h t time function t h t discret howev h t nice pwl function bh t exactli vfp result instead o δ2 multipl f t vfp onli o · δ multipl f t k number linear segment bh t note h t monoton bh t usual close t k δ pi valu rang [ ] vi valu rang [ p mi∈m ri ] vi t bvi t error v pi t bpi t error p now overal approxim error valu function propag phase term p v c≺ set preced constraint dec-mdp tempor constraint p v probabl function valu function approxim error respect overal error π = maxv supt∈ δ ] |v t − bv t | valu function propag phase then |c≺| v + + p p mi∈m ri proof order bound π first induct size c≺ overal error probabl function propag phase π p maxp supt∈ δ ] |p t − bp t | + p induct base n = onli method present oper equat onli onc error π p p = + p induct step suppos π p |c≺| = n + p statement |c≺| = g = m c≺ graph n + edg g = m c≺ subgraph g such c≺ = c≺ − mi mj mj ∈ m sink node g induct assumpt c≺ probabl propag phase error + p now back link mi mj c≺ error onli probabl function name pj factor + p probabl propag phase error c≺ + p c≺ = c≺ ∪ mi mj + p + p < + p thu opportun cost function not p mi∈m ri error singl valu function propag oper z p t v + p |c≺| −1 x mi∈m ri dt < v + p |c≺| −1 x mi∈m ri number valu function propag oper |c≺| total error π valu function propag phase |c≺| v + + p p mi∈m ri opportun cost function section discuss opportun cost function vj0 method mj0 opportun cost function vj0 ik ] k k=0 back method [ mik ] k k=0 directli method mj0 so far same approach [ ] ] opportun cost function vj0 ik method mik back method mj0 minim non-increas function function v j0 ik t = vj0 · q k ∈ k =k pik t approach heurist h heurist opportun cost problem opportun cost function i overestim ii underestim iii starvat situat figur figur valu function method mj0 method mik ] k k=0 valu function propag method [ mik ] k k=0 k k equat opportun cost function vik immedi reward rk opportun cost function vj0 ik m0 onli method method mk then v ik,0 = vik m0 consequ opportun cost method m0 time t equal pk vik,0 t cost then agent a0 method m0 too much incent execut m0 time t consequ probabl p t m0 other agent time t low agent a0 still expect util execut m0 time t expect util later result time t method m0 instead disastr consequ similarli pk vik,0 t underestim agent a0 interest futur method mik ] k k=0 just sixth intl joint conf autonom agent multi-ag system aama chanc immedi reward r0 chanc agent a0 waits4 time t profit instead execut m0 similarli disastr consequ final vj0 way k vj0 ik method mik opportun cost method mj0 similar reason appli such problem starvat method mk short discuss import opportun cost function vj0 such way overestim underestim starvat problem now heurist h opportun cost proof theorem case overestim mission plan figur h split vj0 [ v j0 ik = vj0 · q k ∈ k =k pik ] k k=0 method [ mik ] k k=0 respect also method mik ] k k=0 local reward same time window = estik letik = δ k = k overestim opportun cost t0 ∈ [ δ ] such opportun cost pk k=0 vik t method [ mik ] k k=0 time t ∈ [  δ ] opportun cost vj0 t equat vik t = z pik t vj0 ik t + t dt method mik ] k k=0 kx vik t kx k=0 z pik t vj0 ik t + t dt ≥ kx k=0 z pik t v j0 ik t + t dt = kx k=0 z pik t vj0 t + t y k ∈ k =k pik t + t dt let ∈ ] constant t0 ∈ [ ] such > t0 ∀k=0  k k ∈ k =k pik t c then kx vik t0 kx k=0 z pik t vj0 t0 + t c dt pjk non-decreas now t1 ∈ t0 δ ] such pk r pik t dt > vj0 t0 c·vj0 t1 upper limit integr posit function also integr kx vik t0 c kx k=0 z t1 t0 pik t − t0 vj0 t dt vj0 t non-increas kx vik t0 c · vj0 t1 kx k=0 z t1 t0 pik t − t0 dt c · vj0 t1 kx k=0 z pik t dt > · vj0 t1 vj t0 c · vj t1 = vj t0 let0 t consequ opportun cost pk k=0 vik t0 execut method [ mik ] k k=0 time t ∈ [  δ ] opportun cost vj0 t0 theoremfigur show overestim opportun cost easili observ practic problem opportun cost overestim altern heurist opportun cost function • heurist h onli method mik full reward method mj0 v j0 ik t k ∈ k \ k v j0 ik t = vj0 · q k ∈ k =k pik t heurist h method [ mik ] k k=0 full opportun cost method mj0 number k method method mj0 v j0 ik t k vj0 · q k ∈ k =k pik t k ∈ k • heurist bh normal version h heurist method [ mik ] k k=0 initi full opportun cost method mj0 opportun cost overestim split function sum opportun cost function formal v j0 ik t > < > v h j0 ik t pk v h j0 ik t < vj0 t vj0 t v h j0 ik t pk v h j0 ik t otherwis v h j0 ik t = vj0 · q k ∈ k =k pjk t new heurist now heurist h h not opportun cost proof heurist h opportun cost function vj0 onli method eg mik opportun cost method mj0 thu kx =0 vik t = z pik t vj0 ik t + t dt vj0 non-increas ≤ z pik t vj0 t + t y k ∈ k =k pjk t + t dt ≤ z pik t vj0 t + t dt ≤ vj0 t last inequ also consequ fact vj0 non-increas heurist h similarli kx vik t kx k=0 z pik t k vj0 t + t y k ∈ k =k pjk t + t dt k kx k=0 z pik t vj0 t + t dt k · k · vj0 t = vj0 t heurist bh opportun cost function vj0 definit split such manner pk vik t ≤ vj0 t consequ new heurist h overestim opportun cost sixth intl joint conf autonom agent multi-ag system aama reason new heurist follow h opportun cost method mik reward method mj0 exactli heurist h howev heurist h k − method method mj0 reward starvat starvat opportun cost function heurist h reward method howev sum split opportun cost function h heurist non-zero split opportun cost function h heurist clearli undesir such situat figur heurist h occur mean f+g function g not f onli = g bh heurist definit avoid overestim underestim starvat problem experiment evalu vfp algorithm orthogon improv oc-dec-mdp algorithm experiment evalu part part empir qualiti solut local optim solver oc-dec-mdp vfp differ opportun cost function heurist part runtim vfp oc-dec- mdp algorithm varieti mission plan configur first vfp algorithm gener mission plan configur figur onli method mj0 mi1 mi2 m0 present time window method durat pj0 method mj0 uniform t durat pi2 method mi1 mi2 normal distribut n μ = σ = pi2 = n μ = σ = onli mj0 reward ie = reward execut method mj0 time t result figur x-axi graph time y-axi opportun cost first graph confirm opportun cost function vj0 opportun cost function vi1 vi2 h heurist function vi1 +vi2 not alway vj0 function particular vi1 + vi2 vj0 % heurist h graph function vi1 + vi2 alway vj0 then attent civilian rescu domain figur action execut durat normal distribut n = μ = σ = baselin heurist perform global optim solver true total reward domain figur then reward expect total reward local optim solver discuss heurist figur y-axi expect total reward polici previou result h heurist expect total reward % other heurist abl local optim solver close true total reward then h opportun cost function seri experi scalabl vfp variou mission plan configur perform oc-dec-mdp algorithm benchmark vfp scalabl test configur figur civilian rescu domain method execut durat normal distribut n μ = figur mission plan configur civilian rescu domain b chain n method c tree n method factor d squar mesh n method figur vfp perform civilian rescu domain σ = deadlin = runtim vfp algorithm differ level accuraci differ approxim paramet p v such cumul error solut vfp % % % solut oc- dec-mdp algorithm then algorithm total polici improv iter figur perform vfp algorithm civilian rescu domain y-axi runtim millisecond small domain vfp % ocdec-mdp polici error % comparison global optim not first hour runtim strength opportunist solver oc-dec-mdp next vfp perform difficult domain method long chain figur chain method same time method time later method result figur x-axi number method plot y-axi algorithm runtim logarithm scale domain high perform vfp within % error time oc-decmdp then vfp method tree figur particular tree factor depth same time time horizon then result figur speedup case chain vfp algorithm still time oc-dec-mdp polici error % final vfp domain method n × n mesh c≺ = mi j mk j+1 i n = n j n − particular sixth intl joint conf autonom agent multi-ag system aama figur visual heurist opportun cost figur scalabl experi oc-dec-mdp vfp differ network configur mesh method such configur time horizon probabl final method particular time decreas exponenti time horizon then result figur especi mesh vfp algorithm order magnitud oc-dec-mdp polici % polici oc- decmdp conclus decentr markov decis process dec-mdp veri popular agent-coordin problem veri difficult especi real-world domain paper state-of-the-art heurist solut method dec-mdp oc-dec-mdp recent larg dec-mdp heurist solut method valu function propag vfp orthogon improv oc-dec-mdp i oc-decmdp order magnitud valu function method rather separ valu pair method time interv ii solut qualiti oc-dec-mdp overestim opportun cost oc-dec-mdp term relat work extens ocdec-mdp algorithm ] furthermor section global optim algorithm dec-mdp tempor constraint ] ] unfortun large-scal domain present time oc-dec-mdp other local optim algorithm dec-mdp decpomdp [ ] ] ] yet tradit not uncertain execut time tempor constraint final valu function techniqu context singl agent mdp ] ] howev similarli ] lack global state knowledg fundament issu decentr plan acknowledg materi work darpa/ipto coordin program air forc research laboratori contract no fa875005c0030 author also sven koenig anonym review valuabl comment 