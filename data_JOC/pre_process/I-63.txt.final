optim resourc schedul multiag system comput challeng task particularli valu resourc not addit combinatori problem usag multipl resourc agent stochast environ markov decis process mdp recent year effici resource-alloc algorithm agent resourc valu mdp howev prior work static resource-alloc problem resourc onc then util infinite-horizon mdp model problem combinatori resourc schedul agent onli finit period arriv departur time resourc onli time period comput effici procedur global optim resourc assign agent time empir method context stochast jobschedul domain categori subject descriptor i28 [ artifici intellig ] problem solv control method search i211 [ artifici intellig ] artifici intelligence-multiag system gener term algorithm perform design task optim resourc alloc schedul ubiquit multiag system such optim problem comput difficult due number factor particular valu set resourc agent not addit often case resourc complement util function exponenti larg space resourc bundl veri quickli comput intract further even agent util function nonzero onli small subset possibl resourc bundl optim alloc still comput prohibit problem np-complet [ ] such comput issu recent sever thread work compact model agent prefer idea structur present util function compactli exampl logic formula ] altern directli mechan agent util function resourc alloc directli model ] way process agent resourc util function payoff process particular agent resourc stochast environ util function natur markov decis process action avail resourc represent then veri effici resource-alloc algorithm exponenti speedup straightforward optim problem flat represent combinatori prefer ] howev work resourc alloc prefer resource-parameter mdp assumpt resourc onli onc then agent independ infinite-horizon mdp assumpt realloc resourc possibl domain agent arriv depart dynam paper work resourc alloc mdp-induc prefer discrete-tim schedul problem agent present system finit time interv onli resourc interv particular agent arriv depart arbitrari time interv resourc task finite-horizon mdp problem global optim resourc schedul object alloc resourc agent time sum expect reward context main contribut mixed-integerprogram formul schedul problem global optim resourc assign time execut horizon agent arrival1220 978-81-904262-7-5 rp c ifaama departur interv empir flavor schedul problem agent static resourc assign finite-horizon mdp resourc dynam agent time step rest paper first necessari groundwork section then model formal problem statement section section main result optim program global optim resourc schedul discuss experiment result job-schedul problem section section discuss possibl extens gener method background similarli model previou work resourcealloc mdp-induc prefer ] valu set resourc agent valu mdp polici realiz resourc howev focu work problem larg part optim problem resourc time agent finit arriv departur time agent problem finite-horizon mdp contrast previou work infinite-horizon mdp rest section first necessari background finite-horizon mdp linear-program formul basi solut algorithm section also standard method combinatori resourc flat resourc valu comparison benchmark new model here markov decis stationari finite-domain discrete-tim mdp exampl ] thorough detail develop s a p r s finit set system state a finit set action avail agent p stationari stochast transit function p σ| probabl state σ action state s r stationari reward function r reward action state s given mdp decis problem finit horizon t optim action time step expect valu total reward agent s finit lifetim agent s optim polici then function current state s time horizon optim polici problem greedili respect optim valu function recurs follow system finite-tim bellman equat ] v s t r + x σ p σ| v t + ∀s ∈ s t ∈ [ t ] v s t ∀s ∈ s v s t optim valu state s time t ∈ [ t ] optim valu function easili dynam program follow optim polici π π t probabl action state s time t π t = = argmaxa r + p σ p σ| v t + otherwis abov common way optim valu function therefor optim polici finite-horizon mdp howev also problem follow linear program similarli dual lp infinite-horizon mdp [ ] max x r x t x t subject x σ t + = x s p σ| x s t ∀σ t ∈ [ t ] x s = α s ∀s ∈ s α s initi distribut state space x non-stationari occup measur x t [ ] total expect number time action state s time t optim non-stationari polici occup measur π t = x t x t ∈ s t ∈ [ t ] note standard finite-horizon mdp alway uniformly-optim solut optim initi distribut α therefor optim polici arbitrari constant α particular α x t = π t howev mdp resourc constraint section uniformly-optim polici not gener exist such case α part problem input result polici onli optim particular α result well infinite-horizon mdp variou type constraint [ ] also finite-horizon model easili line complet analog argument [ ] combinatori resourc a straightforward approach set agent m valu resourc stochast plan problem case finite-horizon mdp agent possibl resourc assign time valu correspond mdp then agent valuat possibl resourc bundl time central coordin optim resourc assign time valuat resourc differ time differ agent agent valuat combin possibl time horizon agent m ∈ m mdp arrival-departur time interv τ ∈ [ τa m τd m ] henc agent m mdp time horizon no tm = τd m−τa m+1 bτ global time horizon problem agent mdp τd m < bτ ∀m ∈ m sixth intl joint conf autonom agent multi-ag system aama schedul problem agent static resourc requir finite-horizon mdp agent valuat resourc bundl possibl time horizon [ tm ] ω set resourc agent agent resourc bundl time horizon variabl ψ ∈ ψm possibl pair resourc bundl time horizon agent m × tm valu ψ space bundl exponenti number resourc type |ω| agent m valu vψ m ψ coordin ψ resourc time horizon pair agent alloc indic variabl zψ m ∈ ψ m time τ resourc ω function nm τ ω bundl ψ use ω time τ assumpt agent binari resourc requir alloc problem np-complet even onli singl time step difficulti increas significantli multipl time step number valu ψ problem optim alloc global constraint amount resourc ω agent not avail amount bϕ ω follow integ program max x m∈m x ψ∈ψm zψ mvψ m subject ψ∈ψm zψ ≤ ∀m ∈ m x x ψ∈ψm zψ mnm τ ω bϕ ω ∀τ ∈ [ bτ ] ∀ω ∈ ω first constraint equat agent bundl second constraint total assign resourc ω not time resourc bound schedul problem agent abl dynam resourc agent valu combin bundl time step time horizon variabl ψ ∈ ψm case possibl resourc bundl bundl m time step therefor case p t∈ [ tm ] t possibl resourc bundl differ time slot tm differ time horizon same set equat dynam schedul problem integ program differ differ ψ case number ψ valu exponenti agent s plan horizon tm much program straightforward approach problem enumer solut tm static alloc p [ tm dynam realloc mdp agent veri quickli intract growth number resourc |ω| time horizon tm model problem statement now formal model resourceschedul problem problem input follow compon • m ω bϕ τa m τd m bτ section = s a pm rm αm mdp agent ∈ m without loss gener state action space agent same own transit function pm reward function rm initi condit • ϕm a×ω → map action resourc agent m ϕm ω action agent m resourc ω agent m set resourc not resourc ω not mdp polici action ϕm ω resourc requir binari section assumpt not abov input optim problem global sum rewards-map resourc agent time step δ τ × m × ω → solut feasibl correspond assign resourc agent not global resourc constraint x m δm τ ω bϕ ω ∀ω ∈ ω τ ∈ [ bτ ] flavor resource-schedul problem first formul resourc assign space alloc resourc agent static agent s lifetim second formul reassign resourc agent time step lifetim figur resource-schedul problem agent m = m1 m2 m3 resourc = ω1 ω2 ω3 global problem horizon bτ agent arriv departur time gray box respect solut problem horizont bar agent box bar correspond alloc resourc type figur solut static schedul problem solut agent m1 execut mdp time τ = lock resourc execut time τ note agent m1 hold resourc announc departur time τd m1 = ostens other agent resourc effect thu time τ = resourc ω3 m2 then mdp onli action resourc ω1 ω3 time τ agent m3 resourc ω3 interv τ ∈ [ ] figur possibl solut dynam version same problem resourc agent time step exampl agent m1 use resourc ω2 time τ = execut mdp time τ notic agent not mdp so agent m1 onli abl interv τ ∈ [ ] action not resourc ϕm ω clearli model problem statement number assumpt problem desir solut properti assumpt implic section sixth intl joint conf autonom agent multi-ag system aama b figur illustr solut resource-schedul problem agent resourc static resourc assign resourc assign constant agent lifetim b dynam assign resourc assign time step schedul resource-schedul algorithm proce stage first preprocess step agent mdp process section second mdp global optim problem section agent mdp model previou section agent not necessari resourc action mdp execut agent system other word mdp not exampl problem figur agent m1 resourc time τ = execut mdp similarli agent onli mdp interv ∈ [ ] τ ∈ [ ] respect therefor import part global decision-mak problem window time agent activ mdp agent s mdp new state start finish state sf respect new start/stop action a∗ figur idea agent start state sb readi mdp point start/stop action a∗ transit state space origin mdp transit probabl origin initi distribut α s exampl figur agent m2 time τ onc agent end activ window time τ agent m2 figur start/stop action sink finish state sf time τ precis mdp s a pm rm αm augment mdp s a pm rm αm s = s ∪ ∪ sf a a ∪ a∗ s|sb a∗ = α s ∀s ∈ s p sb |sb = ∀a a p sf |s a∗ ∀s ∈ s p σ| = p σ| σ ∈ s ∈ a r sb = r sf = ∀a a r = r ∀s ∈ s ∈ a α sb α ∀s ∈ s non-specifi transit probabl further order new state mdp time-step τa m τa m not resourc alloc due resourc onli origin mdp state next section exampl augment mdp figur state sb time τ = mdp origin arriv time τ figur also sampl trajectori state space agent state sb transit state space s origin mdp final sink state sf note problem agent mdp arbitrari time step use domain dynam realloc possibl easili extra action transit state reward milp resourc schedul given set augment mdp goal section global optim program resource-schedul problem section mdp augment mdp section approach similar idea [ ] linear-program formul agent mdp augment constraint correspond resourc alloc agent time valid optim problem then simultan agent mdp resource-schedul problem rest section increment mix integ program milp absenc resourc constraint agent finitehorizon mdp complet independ global optim solut trivial follow lp simpli aggreg single-ag finitehorizon lp max x m x rm x t xm t subject xm σ t + = x s pm σ| xm t ∀m ∈ m σ ∈ s t ∈ [ tm ] xm = αm s ∀m ∈ m ∈ s xm t occup measur agent m sixth intl joint conf autonom agent multi-ag system aama b figur illustr mdp variabl start time origin two-stat mdp singl action right augment mdp new state sf new action a∗ note origianl transit not augment process b mdp trajectori time grey line transit black line trajectori object function sum reward agent x m x rm x t xm t implic linear constraint tie x agent onli activ occup measur nonzero origin mdp state θm τ =⇒ xm τ −τa m+1 ∀s /∈ sb sf ∈ a x s/∈ sb sf xm t ≤ θm τa m + − ∀m ∈ m ∀t ∈ [ tm ] agent onli activ τ ∈ τa m τd m θm τ ∀m ∈ m τ /∈ τa m τd m not resourc not activ θm τ =⇒ δm τ ω ∀τ ∈ [ bτ ] ω ∈ ω δm τ ω θm τ ∈ m τ ∈ [ bτ ] ω ∈ ω tie x nonzero x forc δ nonzero δm ω ϕm ω =⇒ xm τ − τa + ∀s /∈ sb sf ϕm ω x s/∈ sb sf xm t ≤ δm t + τa − ω ∈ m ω ∈ ω t ∈ [ tm ] resourc x m δm τ ω bϕ ω ∈ ω τ ∈ [ bτ ] agent not resourc activ onli static assign θm τ θm τ + =⇒ δm τ ω δm τ + ω δm ω − z − θm τ + τ + ω z − θm τ ω + z − θm τ + τ + ω z − θm τ ∈ m ω ∈ ω τ ∈ [ bτ ] tabl milp global optim resourc schedul tm = τd m − τa + time horizon agent s mdp lp basi constraint resourc usag agent occup measur xm not global resourc requir time step τ ∈ [ bτ ] resourc constraint follow binari variabl • δm ω ∀m ∈ m τ ∈ [ bτ ] ω ∈ ω indic variabl agent m resourc ω time τ analog static indic variabl one-shot static resource-alloc problem ] θm = ∀m ∈ m τ ∈ [ bτ ] indic variabl agent m activ mdp time τ mean resource-usag variabl δ figur δm ω onli resourc ω m time τ mean activ indic figur agent m start state sb finish state sf correspond θm = onc agent activ other state θm = mean θ linear constraint valu agent occup measur xm activ sixth intl joint conf autonom agent multi-ag system aama indic tabl constraint activ indic global timelin τ-i fact agent inact arrivaldepartur window constraint tabl furthermor agent not resourc inact constraint also linear inequ θ δ constraint valu θ polici occup measur xm similar fashion sure resource-usag variabl δ also occup measur xm constraint tabl nearli ident analog constraint ] abov constraint mean δ constraint agent resourc usag never amount avail resourc condit also trivial linear inequ tabl final problem formul resourc assign static lifetim agent constraint resource-usag variabl δ not valu agent activ θ = linear constraint z constant constraint θm τ θm τ + = constraint not dynam problem formul resourc agent time step tabl togeth conservationof-flow constraint milp simultan optim resourc assign agent across time as well optim finite-horizon mdp polici valid resourc assign rough measur complex milp number optim variabl constraint tm = p tm = p m τa m − τd + sum length arrival-departur window agent then number optim variabl tm + bτ|m||ω| + bτ|m| tm continu xm bτ|m||ω| + bτ|m| binari δ θ howev notic tm|m| θ constraint also immedi tm|m||ω| δ constraint number constraint not degener constraint milp tm + tm|ω| + bτ|ω| + bτ|m||ω| fact complex milp case exponential1 number binari variabl complex milp significantli exponenti milp flat util function section result effici gain [ ] single-shot resource-alloc problem much pronounc explos flat util represent due tempor aspect problem prohibit complex combinatori optim section empir perform method section strictli milp optim npcomplet number integ variabl experiment result complex milp case exponenti number integ variabl mani effici method milp algorithm well paramet common alloc schedul problem particular section problem domain-th repairshop problem-us empir algorithm s scalabl term number agent number share resourc vari length global time bτ agent system repairshop problem simpl parameter mdp metaphor vehicular repair shop agent repair shop mechan number independ task reward onli mdp model system action state space onli agent certain resourc publicli avail shop resourc finit suppli optim polici shop agent limit resourc action individu reward task singl action agent action numer time task reward model term number agent system number differ type resourc necessari action global time agent maximum length number time step agent system datapoint experi evalu cplex milp pentium4 comput ram trial static dynam version resourceschedul problem figur runtim polici valu independ modif paramet top row solut time milp scale number agent global time horizon bτ number resourc |ω| number agent exponenti complex scale np-complet problem howev global time limit bτ total number resourc type |ω|-while number agent constantdo not decreas perform problem under-constrain also common phenomenon np-complet problem also solut dynam version problem often much static version bottom row figur joint polici valu polici optim resource-alloc schedul dynam version yield reward reward dynam version alway no reward static version graph not measur perform differ algorithm optim solut differ problem rather observ qualiti optim solut flexibl realloc resourc figur show runtim polici valu trial common input variabl togeth sixth intl joint conf autonom agent multi-ag system aama −3 −2 −1 number agent |m| cputim sec |ω| = τ static dynam −2 −1 global time boundari τ cputim sec |m| = |ω| static dynam −2 −1 number resourc |ω| cputim sec |m| = τ static dynam number agent |m| valu |ω| = τ static dynam global time boundari τ valu |m| = |ω| static dynam number resourc |ω| valu |m| = τ static dynam figur evalu milp variabl number agent length global-tim window column number resourc type column top row cpu time bottom row joint reward agent mdp polici error quartil % % −3 −2 −1 number agent |m| cputim sec τ static dynam −3 −2 −1 number agent |m| cputim sec |ω| static dynam −3 −2 −1 number agent |m| cputim sec |ω| static dynam number agent |m| valu τ = static dynam number agent |m| valu |ω| = static dynam number agent |m| valu |ω| = static dynam figur evalu milp input variabl left column perform cpu time number agent global-tim window increas togeth = middl right column perform cpu time number resourc number agent togeth |ω| = |ω| = respect error quartil % % sixth intl joint conf autonom agent multi-ag system aama domain total number agent scale proport total number resourc type global time horizon constant averag agent densiti unit global time averag number resourc agent commonli real-lif applic overal experiment result milp formul effect resource-schedul problem nontrivi size discuss conclus paper number assumpt model solut algorithm implic • continu execut onc agent mdp transit state sf system not easi assumpt domain agent mdp addit paus action transit state back reward • indiffer time reward model agent reward onli time horizon mdp not global start time consequ mdp-augment procedur section easi model agent explicit penalti non-zero neg reward start state sb • binari resourc requir simplic resourc cost binari ϕm ω result straightforward manner non-binari resourc map analog procedur [ ] • cooper agent optim procedur paper context cooper agent also mechan schedul resourc self-interest agent optim procedur vickreyclarke-grov auction complet analog way [ ] fact result [ ] properti auction inform privaci directli domain paper onli slight modif finitehorizon mdp • known determinist arriv departur time final agent arriv departur time τa m τd m determinist priori assumpt fundament solut method mani domain assumpt valid mani case agent arriv dynam arriv departur time onli probabilist resource-alloc problem particular case self-interest agent interest version online-mechanism-design problem [ ] summari milp formul combinatori resource-schedul problem agent valu possibl resourc assign finitehorizon mdp result previou work [ ] static one-shot resourc alloc mdp-induc prefer resource-schedul problem tempor aspect such work step direct onlin mechan agent combinatori resourc prefer stochast plan problem assumpt determinist arriv departur time agent focu futur work anonym review insight comment suggest 