text classifi probabl estim readili applic varieti scenario exampl rather decis threshold bayesian risk model run-tim decis userspecifi cost function dynam predict time howev qualiti probabl crucial varieti standard approach score poor probabl estim text classifi high qualiti estim new model intuit empir score distribut extrem irrelev hard obvious relev item often significantli differ final experiment perform model output text classifi analysi model theoret attract few new paramet flexibl comput effici empir prefer categori subject descriptor h33 [ inform storag retriev ] inform search retriev i26 [ artifici intellig ] learn i52 [ pattern recognit ] design methodolog gener term algorithm experiment reliabl introduct text classifi probabl estim flexibl practic onli simpl classif even rank exampl rather decis threshold bayesian risk model ] runtim decis expect cost user-specifi cost function dynam predict time linear util cost function task pre-specifi cost relevant/irrelev not avail train predict time furthermor cost model addit probabl estim often basi document s label next activ [ ] effect activ learn key mani inform retriev task data costli sever amount data same perform new label randomli [ ] final also amen other type cost-sensit decis ] decis ] howev task qualiti probabl crucial parametr model gener assumpt data conform model trade-off flexibl abil model paramet accur littl data mani text classif task often veri littl train data parametr method howev parametr method task assumpt undesir method distribut document relev irrelev topic differ varianc typic unnecessari constraint document symmetr respect mode sever asymmetr parametr model assumpt significantli number paramet effici model addit model score text classifi basic type empir behavior correspond extrem irrelev hard obvious relev item first relat work probabl estim score model inform retriev then further detail need asymmetr model specif asymmetr model standard text classifi na¨ıv bay svm effici poor probabl estim high qualiti probabl estim raw score then experi previous method asymmetr method sever text classif corpora strength weak variou method final contribut discuss futur direct relat work parametr model probabl estim sever area inform retriev lewi gale ] use logist regress na¨ıv bay qualiti probabl estim not directli simpli intermedi step activ learn manmatha [ ] model probabl estim relev score search engin result probabl estim subsequ output sever search engin differ parametr distribut relev irrelev class not two-sid asymmetr distribut singl class describ here also survey long histori relev score search engin work similar flavor previou attempt search engin score text classifi output differ type score distribut behavior role data focu probabl estim late zadrozni elkan ] correct measur decis tree term curtail non-parametr method na¨ıv bay recent work [ ] semi-parametr method monoton piecewiseconst fit data method bay linear svm method other parametr method symmetri signific test result work asymmetr parametr method non-parametr semi-parametr method data scarciti issu addit method resolut score output classifi number distinct valu output method here not such weak continu function varieti other work paper platt ] logist regress framework model class label probabl raw output svm work post-process method not onli probabl estim similar qualiti svm directli probabl likelihood kernel method also kernel final bennett [ ] moder gain platt s method recalibr na¨ıv bay problemat area svm poorli classifi not new problem lindley et [ ] first idea classifi degroot fienberg ] now accept standard formal problem calibr other [ ] problem definit approach work differ approach primarili point asymmetr parametr model suitabl use littl train data avail explicitli qualiti probabl estim method signific test result text classifi output major previou literatur output search engin problem definit gener problem figur text classifi predict document score s d strength decis document posit class relev topic onli class posit neg irrelev class + respect gener type parametr approach first tri posterior function directli ie p s|+ p s|− bay rulep + p − classifi p +| s d predict class c d + − confid s d d document d unnorm figur box grey intern type approach function estim direct map score s probabl p +| d second type approach problem as grey box figur estim class-condit densiti ie p s|+ p s|− then bay rule class prior estim p +| d motiv asymmetr distribut most previou parametr approach problem directli indirectli onli posterior correspond gaussian class-condit densiti onli criterion paramet figur s usual increas likelihood posit class then rightmost distribut usual s|+ b c −10 p s|class= + − confid score s p s | class = + p s | class = − figur typic view discrimin gaussian howev standard gaussian basic characterist commonli name raw output score discrimin then empir behavior mode label b figur often veri differ outsid mode a c figur intuit area mode correspond hard exampl difficult classifi area mode extrem exampl usual easili scale outsid insid segment distribut curv a-gaussian figur result asymmetr distribut appropri choic applic raw output score classifi ideal ie perfect classif score θ− θ+ such exampl score θ+ relev exampl score θ− irrelev furthermor exampl θ− θ+ distanc | θ− − θ+ | margin classifi attempt often quantiti text classifi data class final behavior score distribut primarili factor amount train data consequ separ class contrast engin retriev distribut score factor languag distribut document similar function length type queri perfect classif correspond veri asymmetr distribut case probabl actual mani method typic purpos practic exampl θ− θ+ often import probabl exampl well hard exampl justif exampl θ− θ+ outsid few empir reason distribut symmetr natur first candid asymmetr distribut common symmetr distribut eg laplac gaussian asymmetr laplac distribut exponenti mode follow manner p x | θ β γ    βγ β+γ [ −β θ − x x ≤ θ β γ > βγ β+γ [ −γ x − θ x > θ θ β γ model paramet θ mode distribut β invers scale exponenti left mode γ invers scale exponenti right notat λ x | θ β γ distribut -300 -200 p s|class= + confid score s gaussian a-gaussian figur gaussian asymmetr gaussian shortcom symmetr distribut vertic line mode nonparametr asymmetr gaussian same manner p x | θ σl σr    σl+σr exp − x−θ l x ≤ θ σl σr > σl+σr exp − x−θ r x > θ θ σl σr model paramet asymmetr gaussian notat γ x | θ σl σr distribut halv function singl continu distribut distribut data much flexibl cost onli paramet instead mixtur model compon other extens other extens mani paramet often comput expens addit motiv signific caus underli distribut actual way furthermor famili distribut still symmetr distribut final empir evalu evid asymmetr behavior figur knowledg famili distribut previous machin learn inform retriev term gener asymmetr laplac [ ] natur task paramet asymmetr distribut section method maximum likelihood estim mle paramet abov asymmetr distribut order mle choic use numer estim paramet onc valu θ other γ σl σr choic θ then altern valu θ simplic analysi latter altern method asymmetr laplac mle d = x1 x2 xn xi x ∼ λ x | θ β γ likelihood n i λ x | θ β γ now θ maximum likelihood choic θ then simpli choic θ one maximum likelihood choic θ complet deriv space avail [ ] follow valu nl = | x ∈ d | x ≤ θ | nr = | x ∈ d | x > θ | sl = x∈d|x≤θ x sr = x∈d|x > θ x dl = nlθ − sl dr = sr − nrθ note dl dr sum absolut differ x belong left right halv distribut respect final mle β γ fix θ βmle = n dl + √ drdl γmle = n dr + √ drdl estim not wholli unexpect nl dl β independ γ eleg formula estim symmetr onli insofar data dictat ie closer dl dr equal invers scale continu argument n β = γ small constant distribut uniform similarli n dl = β = inf inf veri larg constant extrem sharp distribut ie almost mass θ half dr similarli θ rang [ φ ψ ] depend onli observ document then altern also easili comput nl sl nr sr posterior mle constant time addit score then whole process quit effici minimum θ = score onc nl sl nr sr appropri then θ just score right side distribut left number candid θs o n process o n overal process score o n log n linear time asymmetr gaussian mle d = x1 x2 xn xi x ∼ γ x | θ σl σr likelihood n i γ x | θ β γ mle similar abov same definit complet deriv space avail [ ] addit sl2 = x∈d|x≤θ x2 sr2 = x∈d|x > θ x2 dl2 = sl2 − slθ + θ2 nl dr2 = sr2 − srθ + θ2 nr analyt solut mle fix θ σl mle = dl2 + d l2 d r2 n σr mle = dr2 + d r2 d l2 n continu argument n σr = σl = inf n dl2 = resp dr2 = σl resp = same comput complex analysi appli paramet experiment analysi method method class prior smooth add-on estim ie p c |c|+1 n+2 n number document method class-condit densiti p s|+ p s|− densiti bay rule method fit maximum likelihood estim classifi ie poor probabl estim output classifi usual log-odd classifi s estim s d log-odd log p +|d p −|d normal decis threshold error term log-odd zero ie p +|d p −|d output space [ −∞ ∞ ] log-odd make normal similar distribut applic ] lewi gale ] motiv viewpoint log-odd effect inaccur independ assumpt bia correct inaccur estim prior gener log-odd signal origin classifi data dictat gaussian fit class-condit densiti usual maximum likelihood estim method tabl gauss asymmetr gaussian asymmetr gaussian fit class-condit densiti maximum likelihood estim procedur interv adjac score candid θs ie point actual score data set method a gauss laplac distribut even laplac distribut not typic task also method benefit asymmetr form usual mle locat scale classic symmetr laplac distribut [ ] method laplac asymmetr laplac distribut asymmetr laplac fit class-condit densiti maximum likelihood estim procedur abov asymmetr gaussian interv adjac score candid θs method a laplac logist regress method first method directli posterior p +| d method set famili two-paramet sigmoid famili primarili model class label abov method addit boon method complet rank classifi method appropri previou method mostli rank data dictat thu data behavior better cost monoton constraint output classifi lewi gale ] use logist regress na¨ıv bay subsequ use activ learn model p +| d + b s d + exp + b s d instead probabl directli output classifi loglikelihood ratio probabl log p d|+ p d|− score s d instead below logodd ratio not model simpli score constant prior method logreg logist regress noisi class label platt ] framework logist regress model noisi class label probabl estim raw output svm model differ logreg model onli paramet paramet still fit maximum likelihood estim model noisi class label addit possibl class nois finit probabl posit exampl neg exampl nois estim number posit exampl number neg exampl bay rule probabl incorrect label even perform model not much logreg complet method lr+nois data sever corpora msn web directori reuter trec-ap msn web directori msn web directori larg collect heterogen web page may web snapshot hierarch classifi same split document [ ] msn web hierarchi seven-level hierarchi top-level categori class proport train % % test % % class gener subject such health fit travel vacat human index document categori experi onli top word mutual inform class approxim word document reuter reuter corpu ] reuter news articl data set modapt standard train/ test split document unus document class econom subject eg acq acquisit earn earn human tagger document document multipl subject actual class domain onli train set howev onli ten frequent class small number exampl perform measur difficult due high variance1 class result previous result ] class proport train % % test % % experi onli top word mutual inform class approxim word document trec-ap corpu collect ap news stori same split document [ ] [ ] also ] categori keyword keyword field titl bodi field experi twenti categori total class proport train % % test % % experi onli top word mutual inform class approxim word train document classifi classifi evalu linear svm classifi discrimin classifi not normal output probabl valu na¨ıv bay classifi probabl output often poor [ ] [ ] a separ comparison onli logreg lr+nois a laplac categori reuter also varianc evalu also claim here svm linear svm smox toolkit platt s sequenti minim optim algorithm featur continu valu raw output score svm s d appropri [ ] normal decis threshold error classifi zero na¨ıv bay na¨ıv bay model multinomi model ] word class probabl bayesian estim word prior laplac m-estim respect log-odd classifi s d normal decis threshold zero perform measur log-loss [ ] error [ ] qualiti probabl estim document d class c d + − ie data label not probabl δ c d + log p +|d δ c d − log p −|d δ b = b otherwis squar error δ c d + − p +|d + δ c d − − p −|d class document correctli probabl log-loss error class document incorrectli probabl log-loss −∞ squar error thu measur close estim correctli item s class vari harshli incorrect predict onli sum measur averag space averag averag log-loss mean error mse total number binari decis corpu addit also error classifi default threshold probabl probabl estim respect decis threshold p +|d thu onli method fals posit same fals neg not gener qualiti probabl simpli reader complet understand empir tendenc method standard micro sign test ] statist signific differ measur onli method sign test test pair score system null hypothesi number item binomi signific level p experiment methodolog categori consider experi not mutual exclus classif n binari classifi n number class order score method probabl estim five-fold cross-valid train data even comput effici leave-one-out cross-valid na¨ıv bay classifi not desir distribut score result cours applic n-fold cross-valid also possibl result n too low perform final classifi result discuss result na¨ıv bay tabl tabl result probabilist output svm log-loss error2 error msn web gauss agauss laplac alaplac logreg lr+nois na¨ıv bay -109890083 reuter gauss agauss laplac alaplac logreg lr+nois na¨ıv bay -5218452 trec-ap gauss -5787257 agauss laplac alaplac logreg lr+nois na¨ıv bay -190348710 log-loss error2 error msn web gauss a gauss laplac a laplac logreg lr+nois linear svm n/a n/a reuter gauss a gauss -458046 laplac a laplac -259928 logreg lr+nois linear svm n/a n/a trec-ap gauss a gauss laplac a laplac -4841439 logreg lr+nois linear svm n/a n/a tabl result na¨ıv bay b svm right entri corpu bold entri statist significantli other entri underlin † method significantli other method na¨ıv bay a ‡ entri significantli other method a gauss na¨ıv bay tabl left reason distinct signific test text gener observ perform method variou corpora first a laplac lr+nois logreg quit clearli other method usual littl differ perform lr+nois logreg here decis decis basi unsurpris lr+nois just noisi class label logreg model respect differ measur lr+nois logreg slightli never significantli a laplac task respect log-loss error howev a laplac alway number error task though time degre improv not signific order reader sens behavior method figur 4-5 fit competit method actual data behavior nonparametr class earn reuter figur class-condit densiti thu onli a laplac logreg posterior directli figur estim log-odd ie log p earn| d p ¬earn| d log-odd rather posterior usual error estim eye easili thing sign test just win loss item method way onli method na¨ıv bay a gauss ever pairwis win a laplac sometim pairwis win log-loss error even total never win ie heavi penalti addit comparison pairwis win case logreg lr+nois score a laplac not signific sign test level not win exampl binari decis msn web dataset a laplac approxim pairwis win logreg lr+nois no method ever pairwis win a laplac error comparison method total basic observ na¨ıv bay previou work estim veri close [ ] right enough time result not signific sign test size differ here total squar error log-loss bear previou observ wrong realli wrong sever interest point perform asymmetr distribut well first a gauss perform poorli similar bay exampl larg amount behavior result gener tendenc pictur figur crossov tail asymmetr gaussian tend mode much accur symmetr gaussian asymmetr flexibl distanc function too much mass outsid tail mode accur enough figur actual result distribut real data result tail larg discrep likelihood class thu outlier gauss quit competit -600 -400 p s d + s d naiv bay log-odd train test alaplac -15 -10 p s d + s d = linear svm raw score train test alaplac figur empir distribut classifi score document train test set class earn reuter also fit asymmetr laplac distribut train score distribut posit class ie earn distribut right graph neg class ie ¬earn left graph -4 -2 -250 -200 -150 -100 logodds=logp +| d d s d naiv bay log-odd train test alaplac logreg -4 logodds=logp +| d d s d = linear svm raw score train test alaplac logreg figur fit variou method empir log-odd train data class earn reuter a gauss quit heavili enough such case clearli inferior top method howev asymmetr laplac place much emphasi mode figur differ distanc function think sharp peak exponenti result mass mode asymmetr paramet still flexibl standard laplac standard laplac also piecewis fit log-odd space highlight part power asymmetr method sensit knot actual mode rather symmetr assumpt mean correspond mode addit asymmetr method flexibl slope line segment well even case test distribut differ train distribut figur a laplac still solut fit logreg figur next competitor final few observ use variou perform metric first log-loss onli finit amount credit degre someth correct improv ie return zero infinit wrong estim thu possibl total exampl not hand actual util function practic secondli error weak other direct penalti reward [ ] number error small enough possibl method better gener unhelp probabl estim exampl method onli probabl zero na¨ıv bay quit method error just error never log-loss method non-zero probabl outcom reason isol slightli differ insight qualiti estim observ straightforward definit evalu futur promis extens work here hybrid distribut gaussian outsid slope exponenti inner slope empir evid [ ] expect distribut emphasi probabl mass mode exponenti still accur estim tail just logist regress log-odd posterior distribut directli line directli log-odd posterior three-piec line spline instead indirectli same thing asymmetr laplac approach power asymmetri assumpt not assumpt class-condit densiti asymmetr laplac final method output other discrimin classifi open area current appropri method output vote perceptron ] analog log-odd oper score promis log weight perceptron + weight perceptron − summari conclus wide varieti parametr method probabl estim raw score discrimin classifi uncalibr probabilist classifi addit new famili asymmetr behavior discrimin function effici way paramet distribut distribut balanc gener power parametr distribut flexibl ad asymmetr paramet asymmetr gaussian too great emphasi away mode contrast asymmetr laplac distribut prefer sever larg text domain varieti perform measur primari parametr method compar perform sometim varieti logist regress eas paramet distribut good first choic qualiti probabl estim acknowledg grate francisco pereira sign test code anton likhodedov logist regress code john platt code support linear svm classifi toolkit smox also sincer chri meek john platt veri use advic earli stage work thank also jaim carbonel john lafferti use feedback final version paper 