The information processing performance of the system is evaluated using so-called phi -divergences from statistics that quantify "dissimilarity" between probability measures and are intimately related to a number of fundamental limits in statistics and information theory (IT). On optimality in auditory information processing We study limits for the detection and estimation of weak sinusoidal signals in the primary part of the mammalian auditory system using a stochastic Fitzhugh-Nagumo model and an action-recovery model for synaptic depression. We show that there exists a set of parameters that can optimize several important phi -divergences simultaneously and that this set corresponds to a